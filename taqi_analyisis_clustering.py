# -*- coding: utf-8 -*-
"""TAQI_analyisis_Clustering.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/15xP5H-6y2b4OFllgVKnSeQjbrhXj6GF8
"""

#import data
#Import dataset
import pandas as pd
import numpy as np

#insert Air Quality CSV path here:
path = '______________________________'

df = pd.read_csv(path)

#Check data
df.shape

#library
from sklearn.preprocessing import StandardScaler
from sklearn.cluster import KMeans
from sklearn.decomposition import PCA
import matplotlib.pyplot as plt

"""CLUSTERING BY TIME PERIOD (MONTHS)"""

# Convert 'date' column to datetime
df['date'] = pd.to_datetime(df['date'], errors='coerce')

# Extract month from date
df['month'] = df['date'].dt.to_period('M')

# List of relevant pollution columns
pollution_cols = [
    'so2', 'co', 'o3', 'o3_8hr', 'pm10', 'pm2.5',
    'no2', 'nox', 'no', 'co_8hr', 'pm2.5_avg',
    'pm10_avg', 'so2_avg'
]

#Try converting all pollution columns to numeric (coerce errors to NaN)
for col in pollution_cols:
    df[col] = pd.to_numeric(df[col], errors='coerce')

#Select only numeric columns from pollution_cols
numeric_pollution_cols = df[pollution_cols].select_dtypes(include='number').columns

#Group by month and calculate mean
monthly_avg = df.groupby('month')[numeric_pollution_cols].mean()

#display result
print(monthly_avg)

# Impute missing values using column means
monthly_avg_filled = monthly_avg.fillna(monthly_avg.mean())

# Normalize the pollution data
scaler = StandardScaler()
monthly_scaled = scaler.fit_transform(monthly_avg_filled)

# Apply KMeans clustering
k = 3
kmeans = KMeans(n_clusters=k, random_state=42)
monthly_avg_filled['cluster'] = kmeans.fit_predict(monthly_scaled)

# Apply PCA for visualization
pca = PCA(n_components=2)
pca_result = pca.fit_transform(monthly_scaled)
monthly_avg_filled['pca1'] = pca_result[:, 0]
monthly_avg_filled['pca2'] = pca_result[:, 1]

# Plot the clusters
plt.figure(figsize=(10, 6))
for cluster in range(k):
    subset = monthly_avg_filled[monthly_avg_filled['cluster'] == cluster]
    plt.scatter(subset['pca1'], subset['pca2'], label=f'Cluster {cluster}')
plt.title('Monthly Pollution Clusters')
plt.xlabel('PCA Component 1')
plt.ylabel('PCA Component 2')
plt.legend()
plt.grid(True)
plt.tight_layout()
plt.show()

monthly_avg_filled['month'] = monthly_avg.index.astype(str)

cluster_summary = monthly_avg_filled.groupby('cluster')[pollution_cols].mean()
print(cluster_summary)

# This will list which months were assigned to which cluster
print(monthly_avg_filled[['month', 'cluster']])

# See which months belong to each cluster
for c in sorted(monthly_avg_filled['cluster'].unique()):
    print(f"\nCluster {c} months:")
    print(monthly_avg_filled[monthly_avg_filled['cluster'] == c]['month'].tolist())



"""CLUSTERING BY LOCATION"""

# Group by site and compute average pollution per location
location_avg = df.groupby('sitename')[pollution_cols].mean()

# Drop rows with too many missing values or fill with mean
location_avg_filled = location_avg.fillna(location_avg.mean())

# Normalize features
scaler = StandardScaler()
location_scaled = scaler.fit_transform(location_avg_filled)

# KMeans clustering
k = 3
kmeans = KMeans(n_clusters=k, random_state=42)
location_avg_filled['cluster'] = kmeans.fit_predict(location_scaled)

# Dimensionality reduction for plotting
pca = PCA(n_components=2)
pca_result = pca.fit_transform(location_scaled)
location_avg_filled['pca1'] = pca_result[:, 0]
location_avg_filled['pca2'] = pca_result[:, 1]

# Plot clusters
plt.figure(figsize=(10, 6))
for cluster in sorted(location_avg_filled['cluster'].unique()):
    subset = location_avg_filled[location_avg_filled['cluster'] == cluster]
    plt.scatter(subset['pca1'], subset['pca2'], label=f'Cluster {cluster}')
plt.title("Location-Based Pollution Clusters")
plt.xlabel("PCA Component 1")
plt.ylabel("PCA Component 2")
plt.legend()
plt.grid(True)
plt.tight_layout()
plt.show()

print(location_avg_filled[['cluster']])

# Compute cluster-wise pollution averages
cluster_summary = location_avg_filled.groupby('cluster')[pollution_cols].mean()

cluster_summary

# Display sitename and their assigned cluster
# Print the list of locations in each cluster
for c in sorted(location_clusters['cluster'].unique()):
    print(f"\nCluster {c} locations:")
    cluster_sites = location_clusters[location_clusters['cluster'] == c]['sitename'].tolist()
    print(cluster_sites)